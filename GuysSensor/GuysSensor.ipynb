{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#imported stuff\n",
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "import matplotlib.image as mpimg # read image\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#captureing\n",
    "cam = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "timeF = 10  #视频帧计数间隔频率 \n",
    "\n",
    "while(True):\n",
    "    tf, frame = cam.read()\n",
    "    #frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    #upper_red = np.array([130,255,255])\n",
    "    #lower_red = np.array([110,100,100])\n",
    "    #mask = cv2.inRange(frame, lower_red, upper_red)\n",
    "    #frame = cv2.bitwise_and(frame,frame, mask=mask)\n",
    "    if(count%timeF == 0): #每隔timeF帧进行存储操作\n",
    "        cv2.imwrite(\"/Users/max/Downloads/wy/frame1{}.png\".format(count), frame)\n",
    "    count += 1\n",
    "    cv2.imshow('Single Frame', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#functions for processing faces\n",
    "def detectFaces(image_name):\n",
    "    img = cv2.imread(image_name)\n",
    "    face_cascade = cv2.CascadeClassifier('C:/Users/Max/Anaconda3/pkgs/opencv3-3.1.0-py35_0/Library/etc/haarcascades/haarcascade_frontalface_default.xml')\n",
    "    if img.ndim == 3:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = img\n",
    "    faces = face_cascade.detectMultiScale(gray,1.2,5)#检测窗口的大小\n",
    "    result = []\n",
    "    for (x,y,width,height) in faces:\n",
    "        result.append((x,y,x+width,y+height))\n",
    "    return result\n",
    "\n",
    "def saveFacles(image, count):\n",
    "    faces = detectFaces(image)\n",
    "    if faces:\n",
    "        #save_dir = 'image.split('.')[0]+\"_faces\"'\n",
    "        save_dir = 'D:/faces'\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "        #count = 0\n",
    "        for (x1, y1, x2, y2) in faces:\n",
    "            file_name = os.path.join(save_dir,str(count)+\".jpg\")\n",
    "            Image.open(image).crop((x1,y1,x2,y2)).save(file_name)\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#only faces\n",
    "dir = 'D:/DATA/1/'\n",
    "count = 1\n",
    "for file in os.listdir(dir):\n",
    "    iamges = dir + file\n",
    "    saveFacles(iamges, count)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomSizedCrop(64),\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Scale(64),\n",
    "        transforms.CenterCrop(64),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = 'D:/DATA/catdog/64'\n",
    "dsets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
    "         for x in ['train', 'val']}\n",
    "dset_loaders = {x: torch.utils.data.DataLoader(dsets[x], batch_size=4,\n",
    "                                               shuffle=True, num_workers=4)\n",
    "                for x in ['train', 'val']}\n",
    "dset_sizes = {x: len(dsets[x]) for x in ['train', 'val']}\n",
    "dset_classes = dsets['train'].classes\n",
    "\n",
    "test_x,test_y = next(iter(dset_loaders['val']))\n",
    "test_x = Variable(test_x)\n",
    "\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(dsets['train']))\n",
    "print(len(dsets['val']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)    # reproducible\n",
    "\n",
    "# Hyper Parameters\n",
    "EPOCH = 60               # train the training data n times, to save time, we just train 1 epoch\n",
    "BATCH_SIZE = 4\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dset_loaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[dset_classes[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         # input shape (1, 28, 28)\n",
    "            nn.Conv2d(\n",
    "                in_channels=3,              # input height\n",
    "                out_channels=64,            # n_filters\n",
    "                kernel_size=3,              # filter size\n",
    "                stride=1,                   # filter movement/step\n",
    "                padding=1,                  # if want same width and length of this image after con2d, padding=(kernel_size-1)/2 if stride=1\n",
    "            ),                              # output shape (16, 28, 28)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(kernel_size=2),    # choose max value in 2x2 area, output shape (16, 14, 14)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(64, 64, 3, 1, 1),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2),                \n",
    "        )\n",
    "        self.conv3 = nn.Sequential(         \n",
    "            nn.Conv2d(64, 128, 3, 1, 1),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2),                \n",
    "        )\n",
    "        self.conv4 = nn.Sequential(         \n",
    "            nn.Conv2d(128, 128, 3, 1, 1),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2),                \n",
    "        )\n",
    "        self.fc = nn.Linear(128 * 2 * 2, 2)   # fully connected layer, output n classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = x.view(x.size(0), -1)           # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        output = self.fc1(x)\n",
    "        return output, x    # return x for visualization\n",
    "\n",
    "\n",
    "cnn = CNN()\n",
    "print(cnn)  # net architecture\n",
    "\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "loss_func = nn.CrossEntropyLoss()                       # the target label is not one-hotted\n",
    "\n",
    "# following function (plot_with_labels) is for visualization, can be ignored if not interested\n",
    "from matplotlib import cm\n",
    "try: from sklearn.manifold import TSNE; HAS_SK = True\n",
    "except: HAS_SK = False; print('Please install sklearn for layer visualization')\n",
    "def plot_with_labels(lowDWeights, labels):\n",
    "    plt.cla()\n",
    "    X, Y = lowDWeights[:, 0], lowDWeights[:, 1]\n",
    "    for x, y, s in zip(X, Y, labels):\n",
    "        c = cm.rainbow(int(255 * s / 9)); plt.text(x, y, s, backgroundcolor=c, fontsize=9)\n",
    "    plt.xlim(X.min(), X.max()); plt.ylim(Y.min(), Y.max()); plt.title('Visualize last layer'); plt.show(); plt.pause(0.01)\n",
    "\n",
    "#plt.ion()\n",
    "# training and testing\n",
    "for epoch in range(EPOCH):\n",
    "    for step, (x, y) in enumerate(dset_loaders['train']):   # gives batch data, normalize x when iterate train_loader\n",
    "        b_x = Variable(x)   # batch x\n",
    "        b_y = Variable(y)   # batch y\n",
    "\n",
    "        output = cnn(b_x)[0]               # cnn output\n",
    "        loss = loss_func(output, b_y)   # cross entropy loss\n",
    "        optimizer.zero_grad()           # clear gradients for this training step\n",
    "        loss.backward()                 # backpropagation, compute gradients\n",
    "        optimizer.step()                # apply gradients\n",
    "\n",
    "        if step % 50 == 0:\n",
    "            test_output, last_layer = cnn(test_x)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "            accuracy = sum(pred_y == test_y) / float(test_y.size(0))\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data[0], '| test accuracy: %.2f' % accuracy)\n",
    "#            if HAS_SK:\n",
    "                \n",
    "                # Visualization of trained flatten layer (T-SNE)\n",
    "#                tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000)\n",
    "#                plot_only = 500\n",
    "#                low_dim_embs = tsne.fit_transform(last_layer.data.numpy()[:plot_only, :])\n",
    "#                labels = test_y.numpy()[:plot_only]\n",
    "#                plot_with_labels(low_dim_embs, labels)\n",
    "#plt.ioff()\n",
    "\n",
    "# print 10 predictions from test data\n",
    "test_output, _ = cnn(test_x[:10])\n",
    "pred_y = torch.max(test_output, 1)[1].data.numpy().squeeze()\n",
    "print(pred_y, 'prediction number')\n",
    "print(test_y[:10].numpy(), 'real number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save net and parms\n",
    "torch.save(cnn.state_dict(), 'params.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load net and test\n",
    "model = CNN()\n",
    "model.load_state_dict(torch.load('params.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#captureing\n",
    "cam = cv2.VideoCapture(0)\n",
    "timeF = 10  #视频帧计数间隔频率 \n",
    "\n",
    "while(True):\n",
    "    tf, frame = cam.read()\n",
    "    #frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    if(count%timeF == 0): #每隔timeF帧进行存储操作\n",
    "        cv2.imwrite(\"/Users/max/Downloads/wy/00.png\", frame)\n",
    "    cv2.imshow('Single Frame', frame)\n",
    "    image = cv2.imread(\"/Users/max/Downloads/wy/00.png\")\n",
    "    face = saveFacles(image)\n",
    "    face = Variable(face)\n",
    "    output, _ = model(face)\n",
    "    pred_y = torch.max(output, 1)[1].data.numpy().squeeze()\n",
    "    if pred_y == 1:\n",
    "        print(\"tyl\")\n",
    "    if pred_y == 0:\n",
    "        print(\"wy\")\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
