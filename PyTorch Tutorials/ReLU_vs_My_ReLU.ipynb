{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ReLU vs My_ReLU.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "otbHjiypcX-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTfrRw_6ce3-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyReLU(torch.autograd.Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(self, input_):\n",
        "        # 在forward中，需要定义MyReLU这个运算的forward计算过程\n",
        "        # 同时可以保存任何在后向传播中需要使用的变量值\n",
        "        self.save_for_backward(input_)         # 将输入保存起来，在backward时使用\n",
        "        output = input_.clamp(min=0)               # relu就是截断负数，让所有负数等于0\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(self, grad_output):\n",
        "        # 根据BP算法的推导（链式法则），dloss / dx = (dloss / doutput) * (doutput / dx)\n",
        "        # dloss / doutput就是输入的参数grad_output、\n",
        "        # 因此只需求relu的导数，在乘以grad_outpu    \n",
        "        input_, = self.saved_tensors\n",
        "        grad_input = grad_output.clone()\n",
        "        grad_input[input_ < 0] = 0                # 上诉计算的结果就是左式。即ReLU在反向传播中可以看做一个通道选择函数，所有未达到阈值（激活值<0）的单元的梯度都为0\n",
        "        return grad_input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpXH3g3Bpnfz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_relu = MyReLU.apply"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmJEKo0Icnd2",
        "colab_type": "code",
        "outputId": "ddfd2950-58f0-4eaa-b53b-87431a0e668a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "input1 = torch.tensor([-3.0, -1.5,  0.0,  1.5,  3.0],requires_grad=True);input1"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-3.0000, -1.5000,  0.0000,  1.5000,  3.0000], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRusnYfTh_9e",
        "colab_type": "code",
        "outputId": "c93b55f6-7828-4092-c3be-96392a6e3bf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "input2 = torch.tensor([-3.0, -1.5,  0.0,  1.5,  3.0],requires_grad=True);input2"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-3.0000, -1.5000,  0.0000,  1.5000,  3.0000], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Hdbjewcc-QG",
        "colab_type": "code",
        "outputId": "c2e9505c-d3dd-4710-8ed0-53c6b9995a8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# 自定义实现 relu， forward,backward\n",
        "my_res = my_relu(input1);my_res"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000, 0.0000, 0.0000, 1.5000, 3.0000], grad_fn=<MyReLUBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE3TBb0UdLYV",
        "colab_type": "code",
        "outputId": "ef8bef7e-2767-4de8-a450-0910c2b41479",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# pytorch 实现\n",
        "import torch.nn as nn\n",
        "relu = nn.ReLU()\n",
        "py_res = relu(input2);py_res"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000, 0.0000, 0.0000, 1.5000, 3.0000], grad_fn=<ReluBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGjCYEDAdwqV",
        "colab_type": "code",
        "outputId": "7d5981ca-adf8-45d1-e198-a8757c080469",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "my_loss = torch.sum(my_res);my_loss"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.5000, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JH_z9IhGfFhb",
        "colab_type": "code",
        "outputId": "c6c1cafb-5415-427f-9a9d-f69836c96943",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "py_loss = torch.sum(py_res);py_loss"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.5000, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpwFyXVGfWoC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_loss.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxvBqNIFfYkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "py_loss.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnwxFgYSiWiO",
        "colab_type": "code",
        "outputId": "30af4287-dadf-47ac-e021-f8b8a18d74ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "input1.grad"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CU0736k2iZiW",
        "colab_type": "code",
        "outputId": "70fc1340-8576-4621-a718-cc7bc38ee9a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "input2.grad"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZFOymecffTG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 自定义function 继承torch.nn.function，要实现 __init__, forward, backwards方法。\n",
        "# https://zhuanlan.zhihu.com/p/27783097"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGVwZdzBoLBq",
        "colab_type": "code",
        "outputId": "79116be1-add1-47ed-ec0a-6161b3d8381c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        }
      },
      "source": [
        "from torch.autograd import gradcheck\n",
        "\n",
        "# gradchek takes a tuple of tensor as input, check if your gradient\n",
        "# evaluated with these tensors are close enough to numerical\n",
        "# approximations and returns True if they all verify this condition.\n",
        "\n",
        "input_ = Variable(torch.tensor([-2.,-1.,2.]), requires_grad=True)\n",
        "test = gradcheck(MyReLU.apply, input_, eps=1e-6, atol=1e-4)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/autograd/gradcheck.py:239: UserWarning: At least one of the inputs that requires gradient is not of double precision floating point. This check will likely fail if all the inputs are not of double precision floating point. \n",
            "  'At least one of the inputs that requires gradient '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-9b4c66c7fd35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMyReLU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/gradcheck.py\u001b[0m in \u001b[0;36mgradcheck\u001b[0;34m(func, inputs, eps, atol, rtol, raise_exception, check_sparse_nnz)\u001b[0m\n\u001b[1;32m    284\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                     return fail_test('Jacobian mismatch for output %d with respect to input %d,\\n'\n\u001b[0;32m--> 286\u001b[0;31m                                      'numerical:%s\\nanalytical:%s\\n' % (i, j, n, a))\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreentrant\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/gradcheck.py\u001b[0m in \u001b[0;36mfail_test\u001b[0;34m(msg)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfail_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraise_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Jacobian mismatch for output 0 with respect to input 0,\nnumerical:tensor([[0.0000, 0.0000, 0.0000],\n        [0.0000, 0.0000, 0.0000],\n        [0.0000, 0.0000, 0.9537]])\nanalytical:tensor([[0., 0., 0.],\n        [0., 0., 0.],\n        [0., 0., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYApXfV6slDQ",
        "colab_type": "text"
      },
      "source": [
        "### You don’t need to define the backward function, of you use just PyTorch code. Once you need another library, autograd cannot create the backward pass for you.\n",
        "https://discuss.pytorch.org/t/now-that-pytorch-can-autograd-why-we-still-need-to-define-backward-when-defining-customer-function/16200"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzDnuK_ustnX",
        "colab_type": "text"
      },
      "source": [
        "#### 纯pytorch代码不需要自定义backwards方法，pytorch会自己完成，但如果计算过程中调用外部非pytorch库就要自己实现backwards方法。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bD6iMqSarflJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "30c4d218-beac-4a45-a5fa-dd6da388632c"
      },
      "source": [
        "ip = torch.tensor([-2., -1., 0., 1., 2.], requires_grad=True);ip"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-2., -1.,  0.,  1.,  2.], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6i1SALPQrsbx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "75281994-6bd2-4e39-cbbe-da264c6993ac"
      },
      "source": [
        "loss = torch.sum(ip[ip>0]);loss"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3., grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ud8vKt60r1G5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msrmHl14r2XM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0f531481-da9a-41e4-ecdd-36290a047d8a"
      },
      "source": [
        "ip.grad"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    }
  ]
}