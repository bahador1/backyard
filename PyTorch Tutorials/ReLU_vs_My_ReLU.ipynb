{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ReLU vs My_ReLU.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "otbHjiypcX-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTfrRw_6ce3-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyReLU(torch.autograd.Function):\n",
        "\n",
        "    def forward(self, input_):\n",
        "        # 在forward中，需要定义MyReLU这个运算的forward计算过程\n",
        "        # 同时可以保存任何在后向传播中需要使用的变量值\n",
        "        self.save_for_backward(input_)         # 将输入保存起来，在backward时使用\n",
        "        output = input_.clamp(min=0)               # relu就是截断负数，让所有负数等于0\n",
        "        return output\n",
        "\n",
        "    def backward(self, grad_output):\n",
        "        # 根据BP算法的推导（链式法则），dloss / dx = (dloss / doutput) * (doutput / dx)\n",
        "        # dloss / doutput就是输入的参数grad_output、\n",
        "        # 因此只需求relu的导数，在乘以grad_outpu    \n",
        "        input_, = self.saved_tensors\n",
        "        grad_input = grad_output.clone()\n",
        "        grad_input[input_ < 0] = 0                # 上诉计算的结果就是左式。即ReLU在反向传播中可以看做一个通道选择函数，所有未达到阈值（激活值<0）的单元的梯度都为0\n",
        "        return grad_input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79KWlq8nchpm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_relu(input_):\n",
        "    # MyReLU()是创建一个MyReLU对象，\n",
        "    # Function类利用了Python __call__操作，使得可以直接使用对象调用__call__制定的方法\n",
        "    # __call__指定的方法是forward，因此下面这句MyReLU（）（input_）相当于\n",
        "    # return MyReLU().forward(input_)\n",
        "    return MyReLU()(input_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmJEKo0Icnd2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cf16be36-3fe9-4a3b-9664-38a768ffb9f9"
      },
      "source": [
        "input_ = torch.tensor([-3.0000, -1.5000,  0.0000,  1.5000,  3.0000],requires_grad=True);input_"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-3.0000, -1.5000,  0.0000,  1.5000,  3.0000], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Hdbjewcc-QG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2e720639-df8c-4d8e-eda1-7cfd940af91c"
      },
      "source": [
        "# 自定义实现 relu， forward,backward\n",
        "my_res = my_relu(input_);my_res"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000, 0.0000, 0.0000, 1.5000, 3.0000], grad_fn=<MyReLU>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE3TBb0UdLYV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "638694fe-464b-4bfa-9890-b4616cd66885"
      },
      "source": [
        "# pytorch 实现\n",
        "import torch.nn as nn\n",
        "relu = nn.ReLU()\n",
        "py_res = relu(input_);py_res"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000, 0.0000, 0.0000, 1.5000, 3.0000], grad_fn=<ReluBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGjCYEDAdwqV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "172297f0-815e-4c77-a5ca-3dfbfe4a554a"
      },
      "source": [
        "my_loss = torch.sum(my_res);my_loss"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.5000, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JH_z9IhGfFhb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9a04a4b4-8aa5-4da3-eb81-0eb0e7942496"
      },
      "source": [
        "py_loss = torch.sum(py_res);py_loss"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.5000, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpwFyXVGfWoC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_loss.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxvBqNIFfYkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "py_loss.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZFOymecffTG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 自定义function 继承torch.nn.function，要实现 __init__, forward, backwards方法。\n",
        "# https://zhuanlan.zhihu.com/p/27783097"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}