{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weighted loss training on AISHELL and 2018, 0.1+0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '5,6,7'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import Compose\n",
    "from torch.nn import Parameter\n",
    "from torch.autograd import Variable\n",
    "import tensorboardX\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # scipy throws future warnings on fft (known bug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import resource\n",
    "rlimit = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
    "resource.setrlimit(resource.RLIMIT_NOFILE, (2048, rlimit[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n"
     ]
    }
   ],
   "source": [
    "!ulimit -n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentificationDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, path, train, transform=None):\n",
    "        #iden_split_path = os.path.join(path, 'iden_split.txt')\n",
    "        split = pd.read_csv('united_data.csv', sep=',')\n",
    "        split = split.loc[split.duration > 1]                              #get rid of <1s\n",
    "        split = split.sample(frac=1).reset_index(drop=True)                #shuffer\n",
    "        \n",
    "        self.split = split\n",
    "        self.dataset = split['file']\n",
    "        self.phase = split['phase']\n",
    "        self.path = path\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def spectrum(self, wav):\n",
    "        audio_path = wav\n",
    "        # read .wav\n",
    "        rate, samples = wavfile.read(audio_path)\n",
    "        ## parameters\n",
    "        window = 'hamming'\n",
    "        # window width and step size\n",
    "        Tw = 25 # ms\n",
    "        Ts = 10 # ms\n",
    "        # frame duration (samples)\n",
    "        Nw = int(rate * Tw * 1e-3)\n",
    "        Ns = int(rate * (Tw - Ts) * 1e-3)\n",
    "        # overlapped duration (samples)\n",
    "        # 2 ** to the next pow of 2 of (Nw - 1)\n",
    "        nfft = 2 ** (Nw - 1).bit_length()\n",
    "        pre_emphasis = 0.97\n",
    "\n",
    "        # preemphasis filter\n",
    "        samples = np.append(samples[0], samples[1:] - pre_emphasis * samples[:-1])\n",
    "\n",
    "        # removes DC component of the signal and add a small dither\n",
    "        samples = signal.lfilter([1, -1], [1, -0.99], samples)\n",
    "        dither = np.random.uniform(-1, 1, samples.shape)\n",
    "        spow = np.std(samples)\n",
    "        samples = samples + 1e-6 * spow * dither\n",
    "        _, _, spec = signal.spectrogram(samples, rate, window, Nw, Ns, nfft, \n",
    "                                            mode='magnitude', return_onesided=False)\n",
    "        spec *= rate / 10\n",
    "        \n",
    "        return spec\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        phase = self.phase[idx]\n",
    "        # path\n",
    "        track_path = self.dataset[idx] # 'gaoqiong/201709121820301375220201.wav', 'wav/C0001/IC0001W0001.wav'\n",
    "        \n",
    "        if phase == 1:\n",
    "            audio_path = os.path.join(self.path[0], track_path)\n",
    "            samples = self.spectrum(audio_path)\n",
    "            # extract label\n",
    "            label = int(self.split.loc[self.split['file'] == track_path].label)\n",
    "            mask = 0.1\n",
    "\n",
    "            if self.train:\n",
    "                if samples.shape[1] == 300:\n",
    "                    spec = samples\n",
    "                elif samples.shape[1] > 300:\n",
    "                    upper_bound = samples.shape[1] - 300\n",
    "                    start = np.random.randint(0, upper_bound)\n",
    "                    spec = samples[:,start:start+300]\n",
    "                else:#random pick wav to concat under same label\n",
    "                    candit = self.split.loc[self.split.label == label].file.reset_index(drop=True) # signle out wavs\n",
    "                    while(samples.shape[1] <= 300):# if <=300 pick&concat\n",
    "                        intdx = np.random.randint(0, len(candit))\n",
    "                        wav = candit.loc[intdx] #random pick one wav ->'wav/C0001/IC0001W0177.wav'\n",
    "                        wav_path = os.path.join(self.path[0], wav)\n",
    "                        t_sample = self.spectrum(wav_path)\n",
    "                        samples = np.hstack((samples,t_sample)) #concat\n",
    "                    upper_bound = samples.shape[1] - 300\n",
    "                    start = np.random.randint(0, upper_bound)\n",
    "                    spec = samples[:,start:start+300]\n",
    "\n",
    "            if self.transform:\n",
    "                spec = self.transform[0](spec)\n",
    "                \n",
    "        else:\n",
    "            feature_path = os.path.join(self.path[1], track_path[:-3])\n",
    "            feature_path = feature_path + 'npy'\n",
    "\n",
    "            # read .npy\n",
    "            samples = np.load(feature_path)\n",
    "            # extract label\n",
    "            label = int(self.split.loc[self.dataset == track_path].label)\n",
    "            mask = 0.9\n",
    "\n",
    "            if self.train:\n",
    "\n",
    "                if samples.shape[1] == 300:\n",
    "                    spec = samples\n",
    "                elif samples.shape[1] > 300:\n",
    "                    upper_bound = samples.shape[1] - 300\n",
    "                    start = np.random.randint(0, upper_bound)\n",
    "                    spec = samples[:,start:start+300]\n",
    "                else:#random pick wav to concat under same label\n",
    "                    candit = self.split.loc[self.split.label == label].file.reset_index(drop=True) # signle out wavs\n",
    "                    while(samples.shape[1] <= 300):# if <=300 pick&concat\n",
    "                        intdx = np.random.randint(0, len(candit))\n",
    "                        wav = candit.loc[intdx] #random pick one wav\n",
    "                        wav_feature = self.path[1] + wav[:-3] + 'npy'\n",
    "                        t_sample = np.load(wav_feature)\n",
    "                        samples = np.hstack((samples,t_sample)) #concat\n",
    "                    upper_bound = samples.shape[1] - 300\n",
    "                    start = np.random.randint(0, upper_bound)\n",
    "                    spec = samples[:,start:start+300]\n",
    "\n",
    "            else:\n",
    "                spec = samples\n",
    "\n",
    "            if self.transform:\n",
    "                spec = self.transform[1](spec)\n",
    "\n",
    "        return label, spec, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"Convert spectogram to Tensor.\"\"\"\n",
    "    \n",
    "    def __call__(self, spec):\n",
    "        F, T = spec.shape\n",
    "        \n",
    "        # now specs are of size (Freq, Time) and 2D but has to be 3D (channel dim)\n",
    "        spec = spec.reshape(1, F, T)\n",
    "        \n",
    "        # make the ndarray to be of a proper type (was float64)\n",
    "        spec = spec.astype(np.float32)\n",
    "        \n",
    "        return torch.from_numpy(spec)\n",
    "    \n",
    "class Normalize(object):\n",
    "    \"\"\"Normalizes voice spectrogram (mean-varience)\"\"\"\n",
    "    \n",
    "    def __call__(self, spec):\n",
    "        \n",
    "        # (Freq, Time)\n",
    "        # mean-variance normalization for every spectrogram (not batch-wise)\n",
    "        mu = spec.mean(axis=1).reshape(512, 1)\n",
    "        sigma = spec.std(axis=1).reshape(512, 1)\n",
    "        spec = (spec - mu) / sigma\n",
    "\n",
    "        return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clr\n",
    "import math\n",
    "from bisect import bisect_right,bisect_left\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.optim.optimizer import Optimizer\n",
    "\n",
    "class CyclicCosAnnealingLR(_LRScheduler):\n",
    "\n",
    "    def __init__(self, optimizer,milestones, eta_min=0, last_epoch=-1):\n",
    "        if not list(milestones) == sorted(milestones):\n",
    "            raise ValueError('Milestones should be a list of'\n",
    "                             ' increasing integers. Got {}', milestones)\n",
    "        self.eta_min = eta_min\n",
    "        self.milestones=milestones\n",
    "        super(CyclicCosAnnealingLR, self).__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        \n",
    "        if self.last_epoch >= self.milestones[-1]:\n",
    "            return [self.eta_min for base_lr in self.base_lrs]\n",
    "\n",
    "        idx = bisect_right(self.milestones,self.last_epoch)\n",
    "        \n",
    "        left_barrier = 0 if idx==0 else self.milestones[idx-1]\n",
    "        right_barrier = self.milestones[idx]\n",
    "\n",
    "        width = right_barrier - left_barrier\n",
    "        curr_pos = self.last_epoch- left_barrier \n",
    "    \n",
    "        return [self.eta_min + (base_lr - self.eta_min) *\n",
    "               (1 + math.cos(math.pi * curr_pos/ width)) / 2\n",
    "                for base_lr in self.base_lrs]\n",
    "\n",
    "\n",
    "class CyclicLinearLR(_LRScheduler):\n",
    "    \n",
    "    def __init__(self, optimizer,milestones, eta_min=0, last_epoch=-1):\n",
    "        if not list(milestones) == sorted(milestones):\n",
    "            raise ValueError('Milestones should be a list of'\n",
    "                             ' increasing integers. Got {}', milestones)\n",
    "        self.eta_min = eta_min\n",
    "        self.milestones=milestones\n",
    "        super(CyclicLinearLR, self).__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        \n",
    "        if self.last_epoch >= self.milestones[-1]:\n",
    "            return [self.eta_min for base_lr in self.base_lrs]\n",
    "\n",
    "        idx = bisect_right(self.milestones,self.last_epoch)\n",
    "        \n",
    "        left_barrier = 0 if idx==0 else self.milestones[idx-1]\n",
    "        right_barrier = self.milestones[idx]\n",
    "\n",
    "        width = right_barrier - left_barrier\n",
    "        curr_pos = self.last_epoch- left_barrier \n",
    "    \n",
    "        return [self.eta_min + (base_lr - self.eta_min) *\n",
    "               (1. - 1.0*curr_pos/ width)\n",
    "                for base_lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myphi(x,m):\n",
    "    x = x * m\n",
    "    return 1-x**2/math.factorial(2)+x**4/math.factorial(4)-x**6/math.factorial(6) + \\\n",
    "            x**8/math.factorial(8) - x**9/math.factorial(9)\n",
    "\n",
    "class AngleLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, m = 4, phiflag=True):\n",
    "        super(AngleLinear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.Tensor(in_features,out_features))\n",
    "        self.weight.data.uniform_(-1, 1).renorm_(2,1,1e-5).mul_(1e5)\n",
    "        self.phiflag = phiflag\n",
    "        self.m = m\n",
    "        self.mlambda = [\n",
    "            lambda x: x**0,\n",
    "            lambda x: x**1,\n",
    "            lambda x: 2*x**2-1,\n",
    "            lambda x: 4*x**3-3*x,\n",
    "            lambda x: 8*x**4-8*x**2+1,\n",
    "            lambda x: 16*x**5-20*x**3+5*x\n",
    "        ]\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = input   # size=(B,F)    F is feature len\n",
    "        w = self.weight # size=(F,Classnum) F=in_features Classnum=out_features\n",
    "\n",
    "        ww = w.renorm(2,1,1e-5).mul(1e5)\n",
    "        xlen = x.pow(2).sum(1).pow(0.5) # size=B\n",
    "        wlen = ww.pow(2).sum(0).pow(0.5) # size=Classnum\n",
    "\n",
    "        cos_theta = x.mm(ww) # size=(B,Classnum)\n",
    "        cos_theta = cos_theta / xlen.view(-1,1) / wlen.view(1,-1)\n",
    "        cos_theta = cos_theta.clamp(-1,1)\n",
    "\n",
    "        if self.phiflag:\n",
    "            cos_m_theta = self.mlambda[self.m](cos_theta)\n",
    "            theta = Variable(cos_theta.data.acos())\n",
    "            k = (self.m*theta/3.14159265).floor()\n",
    "            n_one = k*0.0 - 1\n",
    "            phi_theta = (n_one**k) * cos_m_theta - 2*k\n",
    "        else:\n",
    "            theta = cos_theta.acos()\n",
    "            phi_theta = myphi(theta,self.m)\n",
    "            phi_theta = phi_theta.clamp(-1*self.m,1)\n",
    "\n",
    "        cos_theta = cos_theta * xlen.view(-1,1)\n",
    "        phi_theta = phi_theta * xlen.view(-1,1)\n",
    "        output = (cos_theta,phi_theta)\n",
    "        return output # size=(B,Classnum,2)\n",
    "\n",
    "\n",
    "class AngleLoss(nn.Module):\n",
    "    def __init__(self, gamma=0):\n",
    "        super(AngleLoss, self).__init__()\n",
    "        self.gamma   = gamma\n",
    "        self.it = 0\n",
    "        self.LambdaMin = 5.0\n",
    "        self.LambdaMax = 1500.0\n",
    "        self.lamb = 1500.0\n",
    "\n",
    "    def forward(self, input, target, mask):\n",
    "        self.it += 1\n",
    "        cos_theta,phi_theta = input\n",
    "        target = target.view(-1,1) #size=(B,1)\n",
    "\n",
    "        index = cos_theta.data * 0.0 #size=(B,Classnum)\n",
    "        index.scatter_(1,target.data.view(-1,1),1)\n",
    "        index = index.byte()\n",
    "        index = Variable(index)\n",
    "\n",
    "        self.lamb = max(self.LambdaMin,self.LambdaMax/(1+0.1*self.it ))\n",
    "        output = cos_theta * 1.0 #size=(B,Classnum)\n",
    "        output[index] -= cos_theta[index]*(1.0+0)/(1+self.lamb)\n",
    "        output[index] += phi_theta[index]*(1.0+0)/(1+self.lamb)\n",
    "\n",
    "        logpt = F.log_softmax(output)\n",
    "        logpt = logpt.gather(1,target)\n",
    "        logpt = logpt.view(-1)\n",
    "        pt = Variable(logpt.data.exp())\n",
    "\n",
    "        loss = -1 * (1-pt)**self.gamma * logpt\n",
    "        \n",
    "        #weighted loss\n",
    "        loss = loss * mask\n",
    "        \n",
    "        loss = loss.mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "\n",
    "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
    "           'resnet152']\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "}\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = conv1x1(inplanes, planes)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = conv3x3(planes, planes, stride)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = conv1x1(planes, planes * self.expansion)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc1 = nn.Linear(512 * block.expansion, 512)\n",
    "        self.fc2 = AngleLinear(512, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x1 = self.fc1(x)\n",
    "        x2 = self.fc2(x1)\n",
    "\n",
    "        return x1, x2\n",
    "\n",
    "\n",
    "def resnet18(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet34(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet50(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet101(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet152(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-152 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = ['/data/hktxt/AISHELL-2/iOS/data/', '/data/hktxt/2018-vad2-features/']\n",
    "LOG_PATH = '/data/hktxt/e/CN/logs/trans_2018_10'\n",
    "EPOCH_NUM = 10\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "B = 96\n",
    "\n",
    "WEIGHT_DECAY = 5e-4\n",
    "LR_INIT = 1e-2\n",
    "LR = 1e-1\n",
    "LR_LAST = 1e-4\n",
    "# lr scheduler parameter\n",
    "gamma = 10 ** (np.log10(LR_LAST / LR_INIT) / (EPOCH_NUM - 1))\n",
    "MOMENTUM = 0.9\n",
    "#DEVICE = \"5,6,7\"\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_WORKERS = 40\n",
    "TBoard = tensorboardX.SummaryWriter(log_dir=LOG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):#µ÷ÕûÑ§Ï°ÂÊ²ßÂÔ£¬ÓÅ»¯Æ÷£¬Ä¿Ç°ÂÖÊý\n",
    "    if epoch <= 20:\n",
    "        lr = LR\n",
    "    elif epoch <= 40:\n",
    "        lr = LR * 0.1\n",
    "    elif epoch <= 60:\n",
    "        lr = LR * 0.01\n",
    "    else:\n",
    "        lr = LR * 0.001\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 3 GPUs!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nmodel_dict = net.state_dict()\\npretrained_dict = torch.load('/data/hktxt/Condadev/voxpy/CN/logs/Res34_ori_1s_1/model_snapshot_30.pkl')\\npretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\\nif pretrained_dict:\\n    model_dict.update(pretrained_dict)\\n    net.load_state_dict(model_dict)\\n    print('sucessed')\\nelse:\\n    print('failed')\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load pretrained model\n",
    "net = resnet50(pretrained=False, num_classes=2365)#1991+374\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "    net = nn.DataParallel(net)\n",
    "    \n",
    "#net.to(DEVICE);\n",
    "\"\"\"\n",
    "model_dict = net.state_dict()\n",
    "pretrained_dict = torch.load('/data/hktxt/Condadev/voxpy/CN/logs/Res34_ori_1s_1/model_snapshot_30.pkl')\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "if pretrained_dict:\n",
    "    model_dict.update(pretrained_dict)\n",
    "    net.load_state_dict(model_dict)\n",
    "    print('sucessed')\n",
    "else:\n",
    "    print('failed')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net.module.fc1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net.module.fc2 = AngleLinear(net.module.fc2.in_features, 374)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms1 = Compose([\n",
    "    Normalize(),\n",
    "    ToTensor()\n",
    "])\n",
    "transforms2 = Compose([\n",
    "    ToTensor()\n",
    "])\n",
    "transforms = [transforms1, transforms2]\n",
    "net.to(DEVICE);\n",
    "\n",
    "trainset = IdentificationDataset(DATASET_PATH, train=True, transform=transforms)\n",
    "trainsetloader = torch.utils.data.DataLoader(trainset, batch_size=B, num_workers=NUM_WORKERS, shuffle=True)\n",
    "\n",
    "#testset = IdentificationDataset(DATASET_PATH, train=False, transform=transforms)\n",
    "#testsetloader = torch.utils.data.DataLoader(testset, batch_size=1, num_workers=NUM_WORKERS)\n",
    "\n",
    "criterion = AngleLoss()\n",
    "optimizer = optim.SGD(net.parameters(), LR_INIT, MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "#lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "#lr_scheduler = CyclicCosAnnealingLR(optimizer,milestones=[30,80],eta_min=1e-6) #clr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 300])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset[1][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "920"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11626"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainsetloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11626it [6:07:45,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11626it [3:43:19,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11626it [3:28:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11626it [3:27:35,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11626it [3:26:56,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11626it [3:25:55,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11626it [3:35:25,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11626it [3:31:01,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11626it [3:27:06,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11626it [3:25:54,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete in 2259m 54s\n",
      "loss @ the end: 0.796\n"
     ]
    }
   ],
   "source": [
    "train_start = time.time()\n",
    "for epoch_num in range(EPOCH_NUM):\n",
    "    #lr_scheduler.step()\n",
    "    adjust_learning_rate(optimizer, epoch_num)\n",
    "    \n",
    "    # train\n",
    "    print('Epoch {}/{}'.format(epoch_num+1, EPOCH_NUM))\n",
    "    net.train()\n",
    "    \n",
    "    for iter_num, (labels, specs, mask) in tqdm(enumerate(trainsetloader)):\n",
    "        optimizer.zero_grad()\n",
    "        labels, specs, mask = labels.to(DEVICE), specs.to(DEVICE), mask.float().to(DEVICE)\n",
    "        _, scores = net(specs)\n",
    "        loss = criterion(scores, labels, mask)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # TBoard\n",
    "        step_num = epoch_num * len(trainsetloader) + iter_num\n",
    "        TBoard.add_scalar('gMetrics/train_loss', loss.item(), step_num)\n",
    "        #TBoard.add_scalar('gMetrics/lr', lr_scheduler.get_lr()[0], step_num)\n",
    "        TBoard.add_scalar('gMetrics/lr', get_lr(optimizer), step_num)\n",
    "    \n",
    "    #save model every epoch\n",
    "    torch.save(net.state_dict(), os.path.join(LOG_PATH, 'model_snapshot_{}.pkl'.format(epoch_num+1)))\n",
    "\n",
    "train_end = time.time() - train_start\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "    train_end // 60, train_end % 60))    \n",
    "\n",
    "# when the training is finished save the model\n",
    "#torch.save(net.state_dict(), os.path.join(LOG_PATH, 'model_snapshot.txt'))\n",
    "TBoard.close()\n",
    "print('loss @ the end: {}'.format(round(loss.item(), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0152, -0.0038,  0.0016,  ..., -0.0184,  0.0031,  0.0195],\n",
       "        [ 0.0090, -0.0167, -0.0012,  ...,  0.0231,  0.0340, -0.0253],\n",
       "        [ 0.0036,  0.0048,  0.0088,  ..., -0.0071, -0.0191,  0.0023],\n",
       "        ...,\n",
       "        [-0.0189, -0.0048, -0.0014,  ..., -0.0034,  0.0057, -0.0007],\n",
       "        [ 0.0156, -0.0060,  0.0034,  ...,  0.0352, -0.0168,  0.0143],\n",
       "        [-0.0031,  0.0017, -0.0050,  ..., -0.0121, -0.0018,  0.0260]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.module.fc2.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
