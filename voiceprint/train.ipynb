{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG-M model with non_local_dot_product trained on vox1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '6,7'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import Compose\n",
    "# from lib.non_local_concatenation import NONLocalBlock2D\n",
    "# from lib.non_local_gaussian import NONLocalBlock2D\n",
    "# from non_local_embedded_gaussian import NONLocalBlock2D\n",
    "from non_local_dot_product import NONLocalBlock2D\n",
    "\n",
    "import tensorboardX\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # scipy throws future warnings on fft (known bug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentificationDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, path, train, transform=None):\n",
    "        iden_split_path = os.path.join(path, 'iden_split.txt')\n",
    "        split = pd.read_table(iden_split_path, sep=' ', header=None, names=['phase', 'path'])\n",
    "        \n",
    "        if train:\n",
    "            phases = [1, 2]\n",
    "        \n",
    "        else:\n",
    "            phases = [3]\n",
    "            \n",
    "        mask = split['phase'].isin(phases)\n",
    "        self.dataset = split['path'][mask].reset_index(drop=True)\n",
    "        self.path = path\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # path\n",
    "        track_path = self.dataset[idx]\n",
    "        audio_path = os.path.join(self.path, 'train', track_path)\n",
    "\n",
    "        # read .wav\n",
    "        rate, samples = wavfile.read(audio_path)\n",
    "        # extract label from path like id10003/L9_sh8msGV59/00001.txt\n",
    "        # subtracting 1 because PyTorch assumes that C_i in [0, 1251-1]\n",
    "        label = int(track_path.split('/')[0].replace('id1', '')) - 1\n",
    "\n",
    "        ## parameters\n",
    "        window = 'hamming'\n",
    "        # window width and step size\n",
    "        Tw = 25 # ms\n",
    "        Ts = 10 # ms\n",
    "        # frame duration (samples)\n",
    "        Nw = int(rate * Tw * 1e-3)\n",
    "        Ns = int(rate * (Tw - Ts) * 1e-3)\n",
    "        # overlapped duration (samples)\n",
    "        # 2 ** to the next pow of 2 of (Nw - 1)\n",
    "        nfft = 2 ** (Nw - 1).bit_length()\n",
    "        pre_emphasis = 0.97\n",
    "        \n",
    "        # preemphasis filter\n",
    "        samples = np.append(samples[0], samples[1:] - pre_emphasis * samples[:-1])\n",
    "        \n",
    "        # removes DC component of the signal and add a small dither\n",
    "        samples = signal.lfilter([1, -1], [1, -0.99], samples)\n",
    "        dither = np.random.uniform(-1, 1, samples.shape)\n",
    "        spow = np.std(samples)\n",
    "        samples = samples + 1e-6 * spow * dither\n",
    "        \n",
    "        if self.train:\n",
    "            # segment selection\n",
    "            segment_len = 3 # sec\n",
    "            upper_bound = len(samples) - segment_len * rate\n",
    "            start = np.random.randint(0, upper_bound)\n",
    "            end = start + segment_len * rate\n",
    "            samples = samples[start:end]\n",
    "            #samples = np.hstack((np.hstack((samples,samples)),samples)) # hstack 3 times\n",
    "        \n",
    "        # spectogram\n",
    "        _, _, spec = signal.spectrogram(samples, rate, window, Nw, Ns, nfft, \n",
    "                                        mode='magnitude', return_onesided=False)\n",
    "        \n",
    "        # just multiplying it by 1600 makes spectrograms in the paper and here \"the same\"\n",
    "        spec *= rate / 10\n",
    "        \n",
    "        if self.transform:\n",
    "            spec = self.transform(spec)\n",
    "\n",
    "        return label, spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize(object):\n",
    "    \"\"\"Normalizes voice spectrogram (mean-varience)\"\"\"\n",
    "    \n",
    "    def __call__(self, spec):\n",
    "        \n",
    "        # (Freq, Time)\n",
    "        # mean-variance normalization for every spectrogram (not batch-wise)\n",
    "        mu = spec.mean(axis=1).reshape(512, 1)\n",
    "        sigma = spec.std(axis=1).reshape(512, 1)\n",
    "        spec = (spec - mu) / sigma\n",
    "\n",
    "        return spec\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert spectogram to Tensor.\"\"\"\n",
    "    \n",
    "    def __call__(self, spec):\n",
    "        F, T = spec.shape\n",
    "        \n",
    "        # now specs are of size (Freq, Time) and 2D but has to be 3D (channel dim)\n",
    "        spec = spec.reshape(1, F, T)\n",
    "        \n",
    "        # make the ndarray to be of a proper type (was float64)\n",
    "        spec = spec.astype(np.float32)\n",
    "        \n",
    "        return torch.from_numpy(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoiceNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(VoiceNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=96, kernel_size=7, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.attention_1 = NONLocalBlock2D(in_channels=256)\n",
    "        #self.attention_2 = NONLocalBlock2D(in_channels=256)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(num_features=96)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=256)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=256)\n",
    "        self.bn4 = nn.BatchNorm2d(num_features=256)\n",
    "        self.bn5 = nn.BatchNorm2d(num_features=256)\n",
    "        self.bn6 = nn.BatchNorm2d(num_features=4096)\n",
    "        self.bn7 = nn.BatchNorm1d(num_features=1024)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "        self.mpool1 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.mpool2 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.mpool5 = nn.MaxPool2d(kernel_size=(5, 3), stride=(3, 2))\n",
    "        \n",
    "        # Conv2d with weights of size (H, 1) is identical to FC with H weights\n",
    "        self.fc6 = nn.Conv2d(in_channels=256, out_channels=4096, kernel_size=(9, 1))\n",
    "        self.fc7 = nn.Linear(in_features=4096, out_features=1024)\n",
    "        self.fc8 = nn.Linear(in_features=1024, out_features=num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.size()\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.mpool1(x)\n",
    "        #x = self.attention_96(x)\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.mpool2(x)\n",
    "        #x = self.attention_256(x)\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.relu(self.bn5(self.conv5(x)))\n",
    "        x = self.mpool5(x)\n",
    "        x = self.attention_1(x)\n",
    "        x = self.relu(self.bn6(self.fc6(x)))\n",
    "        \n",
    "        _, _, _, W = x.size()\n",
    "        self.apool6 = nn.AvgPool2d(kernel_size=(1, W))\n",
    "        x = self.apool6(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.bn7(self.fc7(x)))\n",
    "        x = self.fc8(x)\n",
    "        \n",
    "        # during training, there's no need for SoftMax because CELoss calculates it\n",
    "        if self.train:\n",
    "            return x\n",
    "        \n",
    "        else:\n",
    "            return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '/data/hktxt/voxceleb/'\n",
    "LOG_PATH = '/data/hktxt/Condadev/voxpy/logs/vgg_atten'\n",
    "EPOCH_NUM = 30\n",
    "\n",
    "# in shared code B = 100 but PyTorch throws CUDA out of memory at B = 97 \n",
    "# though B=96 takes only 90.6% of the GPU Mem (bug?):\n",
    "# https://discuss.pytorch.org/t/lesser-memory-consumption-with-a-larger-batch-in-multi-gpu-setup/29087\n",
    "# B = 96\n",
    "# but when \n",
    "torch.backends.cudnn.deterministic = True\n",
    "# I can set B = 100\n",
    "B = 64\n",
    "\n",
    "WEIGHT_DECAY = 5e-4\n",
    "LR_INIT = 1e-2\n",
    "LR_LAST = 1e-4#1e-8\n",
    "# lr scheduler parameter\n",
    "gamma = 10 ** (np.log10(LR_LAST / LR_INIT) / (EPOCH_NUM - 1))\n",
    "MOMENTUM = 0.9\n",
    "#DEVICE = \"5,6,7\"\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_WORKERS = 20\n",
    "TBoard = tensorboardX.SummaryWriter(log_dir=LOG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 2 GPUs!\n"
     ]
    }
   ],
   "source": [
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = DEVICE\n",
    "net = VoiceNet(num_classes=1251)\n",
    "#net.to(DEVICE)\n",
    "#net = nn.DataParallel(net).cuda()\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "    net = nn.DataParallel(net)\n",
    "\n",
    "net.to(DEVICE)\n",
    "#net.cuda()\n",
    "\n",
    "transforms = Compose([\n",
    "    Normalize(),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "trainset = IdentificationDataset(DATASET_PATH, train=True, transform=transforms)\n",
    "trainsetloader = torch.utils.data.DataLoader(trainset, batch_size=B, num_workers=NUM_WORKERS, shuffle=True)\n",
    "\n",
    "testset = IdentificationDataset(DATASET_PATH, train=False, transform=transforms)\n",
    "testsetloader = torch.utils.data.DataLoader(testset, batch_size=1, num_workers=NUM_WORKERS*2)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), LR_INIT, MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2270it [06:39,  6.01it/s]\n",
      "8251it [01:30, 91.16it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2270it [06:29,  6.27it/s]\n",
      "8251it [01:23, 98.33it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2270it [06:30,  6.20it/s]\n",
      "8251it [01:31, 89.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2270it [06:31,  6.16it/s]\n",
      "8251it [01:25, 96.66it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2270it [06:31,  6.05it/s]\n",
      "8251it [01:21, 101.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2270it [06:29,  6.11it/s]\n",
      "8251it [01:23, 98.94it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2270it [06:31,  6.14it/s]\n",
      "8251it [01:18, 105.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2270it [06:28,  6.20it/s]\n",
      "8251it [01:20, 102.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2270it [06:30,  6.17it/s]\n",
      "8251it [01:18, 105.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2270it [06:29,  6.30it/s]\n",
      "8251it [01:20, 111.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2270it [06:52,  6.05it/s]\n",
      "8251it [01:22, 111.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2270it [08:03,  6.07it/s]\n",
      "8251it [01:19, 103.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2270it [06:34,  6.06it/s]\n",
      "8251it [01:32, 91.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2270it [06:31,  6.19it/s]\n",
      "8251it [01:20, 102.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2270it [06:31,  6.34it/s]\n",
      "8251it [01:18, 104.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2270it [06:28,  6.29it/s]\n",
      "8251it [01:19, 107.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2270it [06:29,  6.26it/s]\n",
      "8251it [01:21, 101.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2270it [06:32,  6.10it/s]\n",
      "8251it [01:28, 93.57it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2270it [06:31,  6.19it/s]\n",
      "8251it [01:23, 98.78it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2270it [06:32,  6.13it/s]\n",
      "8251it [01:31, 90.57it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2270it [06:33,  6.04it/s]\n",
      "8251it [01:25, 96.95it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2270it [06:34,  6.01it/s]\n",
      "8251it [01:21, 98.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2270it [06:33,  6.22it/s]\n",
      "8251it [01:27, 94.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2270it [06:33,  6.08it/s]\n",
      "8251it [01:28, 93.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2270it [06:32,  6.05it/s]\n",
      "8251it [01:24, 111.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2270it [06:33,  6.27it/s]\n",
      "8251it [01:33, 88.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2270it [06:33,  6.06it/s]\n",
      "8251it [01:23, 98.29it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2270it [06:34,  6.25it/s]\n",
      "8251it [01:22, 109.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2270it [06:32,  6.09it/s]\n",
      "8251it [01:24, 100.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2270it [06:35,  6.17it/s]\n",
      "8251it [01:30, 91.08it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete in 242m 55s\n",
      "top 1 accuracy @ the end: 0.793\n",
      "top 5 accuracy @ the end: 0.921\n",
      "loss @ the end: 0.164\n"
     ]
    }
   ],
   "source": [
    "train_start = time.time()\n",
    "for epoch_num in range(EPOCH_NUM):\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    # train\n",
    "    print('Epoch {}/{}'.format(epoch_num+1, EPOCH_NUM))\n",
    "    net.train()\n",
    "    \n",
    "    for iter_num, (labels, specs) in tqdm(enumerate(trainsetloader)):\n",
    "        optimizer.zero_grad()\n",
    "        labels, specs = labels.to(DEVICE), specs.to(DEVICE)\n",
    "        #labels, specs = labels.cuda(), specs.cuda()\n",
    "        scores = net(specs)\n",
    "        loss = criterion(scores, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # TBoard\n",
    "        step_num = epoch_num * len(trainsetloader) + iter_num\n",
    "        TBoard.add_scalar('gMetrics/train_loss', loss.item(), step_num)\n",
    "        TBoard.add_scalar('gMetrics/lr', lr_scheduler.get_lr()[0], step_num)\n",
    "        \n",
    "#         TBoard.add_scalar('weights/conv1', net.conv1.weight.mean(), step_num)\n",
    "#         TBoard.add_scalar('weights/conv5', net.conv5.weight.mean(), step_num)\n",
    "#         TBoard.add_scalar('weights/fc6', net.fc6.weight.mean(), step_num)\n",
    "#         TBoard.add_scalar('weights/fc7', net.fc7.weight.mean(), step_num)\n",
    "#         TBoard.add_scalar('weights/fc8', net.fc8.weight.mean(), step_num)\n",
    "#         TBoard.add_scalar('grads/conv1', net.conv1.weight.grad.mean(), step_num)\n",
    "#         TBoard.add_scalar('grads/conv5', net.conv5.weight.grad.mean(), step_num)\n",
    "#         TBoard.add_scalar('grads/fc6', net.fc6.weight.grad.mean(), step_num)\n",
    "#         TBoard.add_scalar('grads/fc7', net.fc7.weight.grad.mean(), step_num)\n",
    "#         TBoard.add_scalar('grads/fc8', net.fc8.weight.grad.mean(), step_num)\n",
    "        \n",
    "    \n",
    "    # test\n",
    "    net.eval()\n",
    "    \n",
    "    top5_accuracy = 0\n",
    "    top1_accuracy = 0\n",
    "\n",
    "    for _, (label, spec) in tqdm(enumerate(testsetloader)):\n",
    "        label, spec = label.to(DEVICE), spec.to(DEVICE)\n",
    "        #labels, specs = labels.cuda(), specs.cuda()\n",
    "        probs = net(spec)\n",
    "\n",
    "        # calculate Top-5 and Top-1 accuracy\n",
    "        pred_top5 = probs.topk(5)[1].view(5)\n",
    "\n",
    "        if label in pred_top5:\n",
    "            # increment top-5 accuracy\n",
    "            top5_accuracy += 1 \n",
    "\n",
    "            if label == pred_top5[0]:\n",
    "                # increment top-1 accuracy\n",
    "                top1_accuracy += 1\n",
    "    \n",
    "    top5_accuracy /= len(testsetloader)\n",
    "    top1_accuracy /= len(testsetloader)\n",
    "\n",
    "    TBoard.add_scalar('gMetrics/test_top5', top5_accuracy, epoch_num)\n",
    "    TBoard.add_scalar('gMetrics/test_top1', top1_accuracy, epoch_num)\n",
    "\n",
    "train_end = time.time() - train_start\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "    train_end // 60, train_end % 60))    \n",
    "\n",
    "# when the training is finished save the model\n",
    "torch.save(net.state_dict(), os.path.join(LOG_PATH, 'model_snapshot.txt'))\n",
    "TBoard.close()\n",
    "print('top 1 accuracy @ the end: {}'.format(round(top1_accuracy, 3)))\n",
    "print('top 5 accuracy @ the end: {}'.format(round(top5_accuracy, 3)))\n",
    "print('loss @ the end: {}'.format(round(loss.item(), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
